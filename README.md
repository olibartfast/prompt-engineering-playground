Sandbox for experimenting with LLM(Large Languange Models) LMM(Large Multimodal Models) and VLM (Vision Language Model)

## Some benchmarks sites
* https://mmmu-benchmark.github.io
* https://lmarena.ai
* https://huggingface.co/spaces/WildVision/vision-arena (paper: https://arxiv.org/pdf/2406.11069)
* https://rank.opencompass.org.cn/home (or https://huggingface.co/spaces/opencompass/open_vlm_leaderboard)

## Online courses
* https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models/


## Vision Multimodal API Services (tentative list)
* https://docs.anthropic.com/en/docs/build-with-claude/vision
* https://platform.openai.com/docs/guides/vision
* https://cloud.google.com/vision?hl=en
* https://azure.microsoft.com/en-us/products/ai-services/ai-vision
* https://aws.amazon.com/rekognition/
* https://platform.stability.ai/docs/api-reference

## Finetuning
* Microsoft Deepspeed:
  * https://github.com/microsoft/DeepSpeed
* Modelscop Swift:
  * https://swift.readthedocs.io/en/latest/Multi-Modal/
* Llama factory:
  * https://github.com/hiyouga/LLaMA-Factory/blob/main/examples/README.md
* InternVL2 (for InternVL models):
  * https://internvl.readthedocs.io/en/latest/internvl2.0/finetune.html
* Huggingface:
  * https://huggingface.co/learn/cookbook/en/fine_tuning_vlm_trl
  * https://www.philschmid.de/fine-tune-multimodal-llms-with-trl

## Inference
  ### OpenAI API-compliant C++ multimodal inference client:
  * [C++ code](OpenAI-completion-client/cpp/Readme.md)
  * [Python code](OpenAI-completion-client/python/Readme.md) (TODO Image Resize in python code)

  ### TensorRT-LLM inference client python/c++
  * TODO check documentation:
     * https://github.com/NVIDIA/TensorRT-LLM/blob/main/examples/multimodal/README.md
     * https://github.com/NVIDIA/TensorRT-LLM/blob/main/examples/cpp/executor/README.md

## Use/rent a gpu cluster in cloud
* https://www.brev.dev/
